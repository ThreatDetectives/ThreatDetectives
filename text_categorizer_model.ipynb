{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model - Threat Detector\n",
    "## Python 401d15 - 01/22/2021\n",
    "### By : Hexx King, Lee Thomas, Taylor Johnson and Ryan Pilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIGGER WARNING! Offensive language and hate speech is visible below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the `read_csv` function, we have passed a parameter for *encoding*, because our data set contains non-english words that's not supported by the default pandas `read_csv` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n0           0      3            0                   0        3      2   \n1           1      3            0                   3        0      1   \n2           2      3            0                   3        0      1   \n3           3      3            0                   2        1      1   \n4           4      6            0                   6        0      1   \n\n                                               tweet  \n0  !!! RT @mayasolovely: As a woman you shouldn't...  \n1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>count</th>\n      <th>hate_speech</th>\n      <th>offensive_language</th>\n      <th>neither</th>\n      <th>class</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dataset = pd.read_csv('./labeled_data.csv', encoding='ISO-8859-1')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 24783 entries, 0 to 24782\nData columns (total 7 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   Unnamed: 0          24783 non-null  int64 \n 1   count               24783 non-null  int64 \n 2   hate_speech         24783 non-null  int64 \n 3   offensive_language  24783 non-null  int64 \n 4   neither             24783 non-null  int64 \n 5   class               24783 non-null  int64 \n 6   tweet               24783 non-null  object\ndtypes: int64(6), object(1)\nmemory usage: 1.3+ MB\n"
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                      count          mean          std  min     25%      50%  \\\nUnnamed: 0          24783.0  12681.192027  7299.553863  0.0  6372.5  12703.0   \ncount               24783.0      3.243473     0.883060  3.0     3.0      3.0   \nhate_speech         24783.0      0.280515     0.631851  0.0     0.0      0.0   \noffensive_language  24783.0      2.413711     1.399459  0.0     2.0      3.0   \nneither             24783.0      0.549247     1.113299  0.0     0.0      0.0   \nclass               24783.0      1.110277     0.462089  0.0     1.0      1.0   \n\n                        75%      max  \nUnnamed: 0          18995.5  25296.0  \ncount                   3.0      9.0  \nhate_speech             0.0      7.0  \noffensive_language      3.0      9.0  \nneither                 0.0      9.0  \nclass                   1.0      2.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Unnamed: 0</th>\n      <td>24783.0</td>\n      <td>12681.192027</td>\n      <td>7299.553863</td>\n      <td>0.0</td>\n      <td>6372.5</td>\n      <td>12703.0</td>\n      <td>18995.5</td>\n      <td>25296.0</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>24783.0</td>\n      <td>3.243473</td>\n      <td>0.883060</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>hate_speech</th>\n      <td>24783.0</td>\n      <td>0.280515</td>\n      <td>0.631851</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>offensive_language</th>\n      <td>24783.0</td>\n      <td>2.413711</td>\n      <td>1.399459</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>neither</th>\n      <td>24783.0</td>\n      <td>0.549247</td>\n      <td>1.113299</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>class</th>\n      <td>24783.0</td>\n      <td>1.110277</td>\n      <td>0.462089</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   class                                              tweet\n0      2  !!! RT @mayasolovely: As a woman you shouldn't...\n1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dt_transformed = dataset[['class', 'tweet']]\n",
    "dt_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   class                                              tweet  \\\n0      2  !!! RT @mayasolovely: As a woman you shouldn't...   \n1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n\n                                tweet_wo_RT_username  \n0  !!!   As a woman you shouldn't complain about ...  \n1  !!!!!   boy dats cold...tyga dwn bad for cuffi...  \n2  !!!!!!!   Dawg!!!!   You ever fuck a bitch and...  \n3                !!!!!!!!!    she look like a tranny  \n4  !!!!!!!!!!!!!   The shit you hear about me mig...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>tweet</th>\n      <th>tweet_wo_RT_username</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n      <td>!!!   As a woman you shouldn't complain about ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n      <td>!!!!!   boy dats cold...tyga dwn bad for cuffi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n      <td>!!!!!!!   Dawg!!!!   You ever fuck a bitch and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n      <td>!!!!!!!!!    she look like a tranny</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n      <td>!!!!!!!!!!!!!   The shit you hear about me mig...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#remove user names by pulling all the characters inbetween \"@\" and \":\"\n",
    "#removes hashtags and their text\n",
    "#removes text starting with http\n",
    "#removes the \"RT\"\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_RT_user(text):\n",
    "    tweet = re.sub(\"@[^\\s]+\", \"\", text)\n",
    "    # hashtag = re.sub(\"#[^\\s]+\", \"\", tweet)\n",
    "    hashtag = re.sub(\"#[\\w|\\d]+\", \"\", tweet)\n",
    "    remove_http = re.sub(\"(https?[a-zA-Z0-9]+)|(http?[a-zA-Z0-9]+)\", \"\", hashtag)\n",
    "    no_rt = re.sub(\"RT\", \"\", remove_http)\n",
    "    return no_rt\n",
    "\n",
    "dt_transformed['tweet_wo_RT_username'] = dt_transformed['tweet'].apply(lambda x: remove_RT_user(x))\n",
    "dt_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   class                                              tweet  \\\n0      2  !!! RT @mayasolovely: As a woman you shouldn't...   \n1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n\n                                tweet_wo_RT_username  \\\n0  !!!   As a woman you shouldn't complain about ...   \n1  !!!!!   boy dats cold...tyga dwn bad for cuffi...   \n2  !!!!!!!   Dawg!!!!   You ever fuck a bitch and...   \n3                !!!!!!!!!    she look like a tranny   \n4  !!!!!!!!!!!!!   The shit you hear about me mig...   \n\n                          tweet_wo_RT_username_punct  \n0     As a woman you shouldnt complain about clea...  \n1     boy dats coldtyga dwn bad for cuffin dat ho...  \n2     Dawg   You ever fuck a bitch and she start ...  \n3                             she look like a tranny  \n4     The shit you hear about me might be true or...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>tweet</th>\n      <th>tweet_wo_RT_username</th>\n      <th>tweet_wo_RT_username_punct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n      <td>!!!   As a woman you shouldn't complain about ...</td>\n      <td>As a woman you shouldnt complain about clea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n      <td>!!!!!   boy dats cold...tyga dwn bad for cuffi...</td>\n      <td>boy dats coldtyga dwn bad for cuffin dat ho...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n      <td>!!!!!!!   Dawg!!!!   You ever fuck a bitch and...</td>\n      <td>Dawg   You ever fuck a bitch and she start ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n      <td>!!!!!!!!!    she look like a tranny</td>\n      <td>she look like a tranny</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n      <td>!!!!!!!!!!!!!   The shit you hear about me mig...</td>\n      <td>The shit you hear about me might be true or...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# removing punctuation\n",
    "\n",
    "import string\n",
    "print(string.punctuation)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punct=[words for words in text if words not in string.punctuation]\n",
    "    words_wo_punct=''.join(no_punct)\n",
    "    return words_wo_punct\n",
    "\n",
    "dt_transformed['tweet_wo_RT_username_punct'] = dt_transformed['tweet_wo_RT_username'].apply(lambda x: remove_punctuation(x))\n",
    "dt_transformed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword = nltk.corpus.stopwords.words('english')\n",
    "# print(stopword[:11])\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     text = [word for word in text if word not in stopword]\n",
    "#     return text\n",
    "\n",
    "# dt_transformed['tweet_wo_RT_username_punct_stopwords'] = dt_transformed['tweet_wo_RT_username_punct'].apply(lambda x: remove_stopwords(x))\n",
    "# dt_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   class                                              tweet  \\\n0      2  !!! RT @mayasolovely: As a woman you shouldn't...   \n1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n\n                                tweet_wo_RT_username  \\\n0  !!!   As a woman you shouldn't complain about ...   \n1  !!!!!   boy dats cold...tyga dwn bad for cuffi...   \n2  !!!!!!!   Dawg!!!!   You ever fuck a bitch and...   \n3                !!!!!!!!!    she look like a tranny   \n4  !!!!!!!!!!!!!   The shit you hear about me mig...   \n\n                          tweet_wo_RT_username_punct  \\\n0     As a woman you shouldnt complain about clea...   \n1     boy dats coldtyga dwn bad for cuffin dat ho...   \n2     Dawg   You ever fuck a bitch and she start ...   \n3                             she look like a tranny   \n4     The shit you hear about me might be true or...   \n\n                    tweet_wo_RT_username_punct_split  \n0  [, As, a, woman, you, shouldnt, complain, abou...  \n1  [, boy, dats, coldtyga, dwn, bad, for, cuffin,...  \n2  [, Dawg, You, ever, fuck, a, bitch, and, she, ...  \n3                     [, she, look, like, a, tranny]  \n4  [, The, shit, you, hear, about, me, might, be,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>tweet</th>\n      <th>tweet_wo_RT_username</th>\n      <th>tweet_wo_RT_username_punct</th>\n      <th>tweet_wo_RT_username_punct_split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n      <td>!!!   As a woman you shouldn't complain about ...</td>\n      <td>As a woman you shouldnt complain about clea...</td>\n      <td>[, As, a, woman, you, shouldnt, complain, abou...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n      <td>!!!!!   boy dats cold...tyga dwn bad for cuffi...</td>\n      <td>boy dats coldtyga dwn bad for cuffin dat ho...</td>\n      <td>[, boy, dats, coldtyga, dwn, bad, for, cuffin,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n      <td>!!!!!!!   Dawg!!!!   You ever fuck a bitch and...</td>\n      <td>Dawg   You ever fuck a bitch and she start ...</td>\n      <td>[, Dawg, You, ever, fuck, a, bitch, and, she, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n      <td>!!!!!!!!!    she look like a tranny</td>\n      <td>she look like a tranny</td>\n      <td>[, she, look, like, a, tranny]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n      <td>!!!!!!!!!!!!!   The shit you hear about me mig...</td>\n      <td>The shit you hear about me might be true or...</td>\n      <td>[, The, shit, you, hear, about, me, might, be,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Tokenization = splitting strings into words\n",
    "\n",
    "def tokenize(text):\n",
    "    split = re.split(\"\\W+\", text)\n",
    "    return split\n",
    "\n",
    "dt_transformed['tweet_wo_RT_username_punct_split'] = dt_transformed['tweet_wo_RT_username_punct'].apply(lambda x: tokenize(x))\n",
    "dt_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "tweets = dt_transformed[['tweet']]\n",
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['',\n  'As',\n  'a',\n  'woman',\n  'you',\n  'shouldnt',\n  'complain',\n  'about',\n  'cleaning',\n  'up',\n  'your',\n  'house',\n  'amp',\n  'as',\n  'a',\n  'man',\n  'you',\n  'should',\n  'always',\n  'take',\n  'the',\n  'trash',\n  'out'],\n ['',\n  'boy',\n  'dats',\n  'coldtyga',\n  'dwn',\n  'bad',\n  'for',\n  'cuffin',\n  'dat',\n  'hoe',\n  'in',\n  'the',\n  '1st',\n  'place'],\n ['',\n  'Dawg',\n  'You',\n  'ever',\n  'fuck',\n  'a',\n  'bitch',\n  'and',\n  'she',\n  'start',\n  'to',\n  'cry',\n  'You',\n  'be',\n  'confused',\n  'as',\n  'shit'],\n ['', 'she', 'look', 'like', 'a', 'tranny']]"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Sliced this output down to 4 items\n",
    "[tweet for tweet in dt_transformed['tweet_wo_RT_username_punct_split'][:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'as': 5,\n 'woman': 36,\n 'you': 37,\n 'shouldnt': 29,\n 'complain': 11,\n 'about': 1,\n 'cleaning': 9,\n 'up': 35,\n 'your': 38,\n 'house': 22,\n 'amp': 3,\n 'man': 24,\n 'should': 28,\n 'always': 2,\n 'take': 31,\n 'the': 32,\n 'trash': 34,\n 'out': 25,\n 'boy': 8,\n 'dats': 15,\n 'coldtyga': 10,\n 'dwn': 17,\n 'bad': 6,\n 'for': 19,\n 'cuffin': 13,\n 'dat': 14,\n 'hoe': 21,\n 'in': 23,\n '1st': 0,\n 'place': 26,\n 'dawg': 16,\n 'ever': 18,\n 'fuck': 20,\n 'bitch': 7,\n 'and': 4,\n 'she': 27,\n 'start': 30,\n 'to': 33,\n 'cry': 12}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "\n",
    "# importing the CountVectorizer to \"vectorize\" sentences by creating a collection of unique words and assigning an index to each one \n",
    "\n",
    "tweets = dt_transformed['tweet_wo_RT_username_punct_split']\n",
    "\n",
    "# `explode()` produces the same as `tweet_list = [item for sublist in tweets for item in sublist]`\n",
    "tweet_list = tweets.explode()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "#Sliced this output down to 50 items\n",
    "vectorizer.fit(tweet_list[:50])\n",
    "vectorizer.vocabulary_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# transforming into feature vectors for the learning model\n",
    "\n",
    "# sliced this output down to 10 items \n",
    "vectorizer.transform(tweet_list[:10]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[list(['', 'As', 'a', 'woman', 'you', 'shouldnt', 'complain', 'about', 'cleaning', 'up', 'your', 'house', 'amp', 'as', 'a', 'man', 'you', 'should', 'always', 'take', 'the', 'trash', 'out'])\n list(['', 'boy', 'dats', 'coldtyga', 'dwn', 'bad', 'for', 'cuffin', 'dat', 'hoe', 'in', 'the', '1st', 'place'])\n list(['', 'Dawg', 'You', 'ever', 'fuck', 'a', 'bitch', 'and', 'she', 'start', 'to', 'cry', 'You', 'be', 'confused', 'as', 'shit'])\n ...\n list(['young', 'buck', 'wanna', 'eat', 'dat', 'nigguh', 'like', 'I', 'aint', 'fuckin', 'dis', 'up', 'again'])\n list(['youu', 'got', 'wild', 'bitches', 'tellin', 'you', 'lies'])\n list(['Ruffled', 'Ntac', 'Eileen', 'Dahlia', 'Beautiful', 'color', 'combination', 'of', 'pink', 'orange', 'yellow', 'amp', 'white', 'A', 'Coll', 'tcoH0dYEBvnZB'])]\n[2 1 1 ... 1 1 2]\n"
    }
   ],
   "source": [
    "\n",
    "# Split the data into testing and training sets\n",
    "\n",
    "tweet_text = tweets.values\n",
    "print(tweet_text) # checking to make sure this is the value I want\n",
    "y = dt_transformed['class'].values\n",
    "print(y) # checking to make sure this is the value I want\n",
    "\n",
    "tweet_text_train, tweet_text_test, y_train, y_test = train_test_split(tweet_text, y, test_size=0.25, random_state=1000)\n",
    "# random_state shuffles the data so that we don't accidently end up with biased data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<247880x19848 sparse matrix of type '<class 'numpy.int64'>'\n\twith 219266 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# creating  the feature vectors in the training set and testing set.\n",
    "\n",
    "X_train = [item for sublist in tweet_text_train for item in sublist]\n",
    "X_test = [item for sublist in tweet_text_test for item in sublist]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test  = vectorizer.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [247880, 18587]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-162cb3a87999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codefellows/401/projects/ThreatDetectives/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[0;32m~/codefellows/401/projects/ThreatDetectives/.venv/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codefellows/401/projects/ThreatDetectives/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codefellows/401/projects/ThreatDetectives/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codefellows/401/projects/ThreatDetectives/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [247880, 18587]"
     ]
    }
   ],
   "source": [
    "\n",
    "# LogisticRegression gives our training model a grade based off it's performance on the testing set\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1611125055244",
   "display_name": "Python 3.9.1 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}